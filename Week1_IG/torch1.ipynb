{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a5dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0ee0ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47fe8340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, device=device)\n",
    "y = torch.tensor([1, 2, 3, 4, 5], device=device)\n",
    "\n",
    "print(torch.mul(x,y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eee7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        \n",
    "        return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_prime(x):\n",
    "        a = NeuralNetwork.sigmoid(x)\n",
    "        return a * (1 - a)\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        # Stability fix: subtract max for numerical stability\n",
    "        exp_shifted = torch.exp(x - torch.max(x, dim=0, keepdim=True))\n",
    "        return exp_shifted / torch.sum(exp_shifted, dim=0, keepdim=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def cross_entropy_loss(y_true, y_pred):\n",
    "        # Add epsilon to avoid log(0)\n",
    "        eps = 1e-12\n",
    "        return -torch.mean(y_true * torch.log(y_pred + eps))\n",
    "\n",
    "    @staticmethod\n",
    "    def cross_entropy_derivative(y_true, y_pred):\n",
    "        y_true = y_true.astype(torch.float32)\n",
    "        return y_pred - y_true\n",
    "\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.costs = []\n",
    "        self.iters = []\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.Layers = len(layer_sizes)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device('cuda')\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "\n",
    "        for k in range(self.Layers - 1):\n",
    "            # Xavier initialization for sigmoid\n",
    "            self.weights.append((torch.from_numpy(np.random.randn(layer_sizes[k + 1], layer_sizes[k]) * np.sqrt(1. / layer_sizes[k]))).to(device=device))\n",
    "            self.biases.append((torch.from_numpy(np.zeros((layer_sizes[k + 1], 1)))).to(device=device))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.activations = [X]\n",
    "        self.Z = []\n",
    "\n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            z = torch.matmul(w, self.activations[-1]) + b\n",
    "            self.Z.append(z)\n",
    "\n",
    "            if i == self.Layers - 2:\n",
    "                a = NeuralNetwork.softmax(z)\n",
    "            else:\n",
    "                a = NeuralNetwork.sigmoid(z)\n",
    "\n",
    "            self.activations.append(a)\n",
    "\n",
    "        return self.activations[-1]\n",
    "\n",
    "    def backward(self, X, y):\n",
    "        dw = [None] * (self.Layers - 1)\n",
    "        db = [None] * (self.Layers - 1)\n",
    "        dz = [None] * (self.Layers)\n",
    "\n",
    "        y_pred = self.activations[-1]\n",
    "        cost = NeuralNetwork.cross_entropy_loss(y, y_pred)\n",
    "\n",
    "        # Last layer derivative\n",
    "        dz[-1] = NeuralNetwork.cross_entropy_derivative(y, y_pred)\n",
    "\n",
    "        for l in reversed(range(self.Layers - 1)):\n",
    "            a_prev = self.activations[l]\n",
    "            dz_current = dz[l + 1]\n",
    "\n",
    "            dw[l] = torch.dot(dz_current, a_prev.T) / X.shape[1]\n",
    "            db[l] = torch.sum(dz_current, dim=1, keepdim=True) / X.shape[1]\n",
    "\n",
    "            if l != 0:\n",
    "                da_prev = torch.dot(self.weights[l].T, dz_current)\n",
    "                dz[l] = da_prev * NeuralNetwork.sigmoid_prime(self.Z[l - 1])\n",
    "\n",
    "        return cost, dw, db\n",
    "\n",
    "    def train(self, X, y, alpha=0.1, epochs=1000):\n",
    "        for i in range(epochs):\n",
    "            self.forward(X)\n",
    "            cost, dw, db = self.backward(X, y)\n",
    "\n",
    "            if i % (epochs // 10) == 0 or i == epochs - 1:\n",
    "                self.costs.append(cost)\n",
    "                self.iters.append(i)\n",
    "                print(f\"Epoch {i}, Cost: {cost:.4f}\")\n",
    "\n",
    "            for j in range(self.Layers - 1):\n",
    "                self.weights[j] -= alpha * dw[j]\n",
    "                self.biases[j] -= alpha * db[j]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "    def evaluate(self, X, y_true):\n",
    "        y_pred = self.forward(X)\n",
    "        pred_labels = torch.argmax(y_pred, dim=0)\n",
    "        true_labels = torch.argmax(y_true, dim=0)\n",
    "        accuracy = torch.mean(pred_labels == true_labels)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fcac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layer_sizes: list):\n",
    "        self.Layers = len(layer_sizes)\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.costs = []\n",
    "        self.iters = []\n",
    "\n",
    "        for i in range(self.Layers - 1):\n",
    "            w = torch.zeros((layer_sizes[i + 1], layer_sizes[i]), dtype=torch.double, device=device, requires_grad=True)\n",
    "            b = torch.zeros((layer_sizes[i + 1], 1), dtype=torch.double, device=device, requires_grad=True)\n",
    "            self.weights.append(w)\n",
    "            self.biases.append(b)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "    def sigmoid_prime(self, x):\n",
    "        a = self.sigmoid(x)\n",
    "        return a * (1 - a)\n",
    "\n",
    "    def softmax(self, x):\n",
    "        return F.softmax(x, dim=0)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.activations = [X]\n",
    "        self.Z = []\n",
    "\n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            z = torch.matmul(w, self.activations[i]) + b\n",
    "            self.Z.append(z)\n",
    "            if i == len(self.weights) - 1:\n",
    "                a = self.softmax(z)\n",
    "            else:\n",
    "                a = self.sigmoid(z)\n",
    "            self.activations.append(a)\n",
    "\n",
    "        return self.activations[-1]\n",
    "\n",
    "    def calculate_loss(self, y_true, y_pred):\n",
    "        return -torch.sum(y_true * torch.log(y_pred + 1e-9), dim=0).mean()\n",
    "\n",
    "    def backward(self, X, y):\n",
    "        y_pred = self.activations[-1]\n",
    "        cost = self.calculate_loss(y, y_pred)\n",
    "\n",
    "        cost.backward()  # Use autograd!\n",
    "\n",
    "        grads_w = [w.grad.clone() for w in self.weights]\n",
    "        grads_b = [b.grad.clone() for b in self.biases]\n",
    "\n",
    "        # Reset gradients manually\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            w.grad.zero_()\n",
    "            b.grad.zero_()\n",
    "\n",
    "        return cost.item(), grads_w, grads_b\n",
    "\n",
    "    def train(self, X, y, alpha=0.01, epochs=1000):\n",
    "        for i in range(epochs):\n",
    "            y_pred = self.forward(X)\n",
    "            cost, grads_w, grads_b = self.backward(X, y)\n",
    "\n",
    "            if i % (epochs // 10) == 0:\n",
    "                self.costs.append(cost)\n",
    "                self.iters.append(i)\n",
    "                print(f\"Epoch {i}, Cost: {cost:.4f}\")\n",
    "\n",
    "            # Manual gradient descent\n",
    "            with torch.no_grad():\n",
    "                for j in range(self.Layers - 1):\n",
    "                    self.weights[j] -= alpha * grads_w[j]\n",
    "                    self.biases[j] -= alpha * grads_b[j]\n",
    "\n",
    "        return\n",
    "\n",
    "    def predict(self, X):\n",
    "        output = self.forward(X)\n",
    "        return output\n",
    "\n",
    "    def evaluate(self, X, y_true):\n",
    "        y_pred = self.predict(X)\n",
    "        pred_labels = torch.argmax(y_pred, dim=0)\n",
    "        true_labels = torch.argmax(y_true, dim=0)\n",
    "        return (pred_labels == true_labels).float().mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e60ec337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def load_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n",
    "        return images\n",
    "\n",
    "def load_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        magic, num = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        return labels\n",
    "\n",
    "train_images = load_images('input/train-images.idx3-ubyte')/255\n",
    "train_labels = load_labels('input/train-labels.idx1-ubyte')\n",
    "test_images = load_images('input/t10k-images.idx3-ubyte')/255\n",
    "test_labels = load_labels('input/t10k-labels.idx1-ubyte')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41aeed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_train_images = (torch.from_numpy(train_images.reshape(60000, 28*28).T)).to('cuda')\n",
    "flat_test_images = (torch.from_numpy(test_images.reshape(10000, 28*28).T)).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d74da67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, num_classes=10):\n",
    "    return np.eye(num_classes)[y].T  # shape: (10, batch_size)\n",
    "\n",
    "y_train = (torch.from_numpy(one_hot(train_labels))).to('cuda')\n",
    "y_test = (torch.from_numpy(one_hot(test_labels))).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42359745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 28.58%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork([784, 64, 16, 10])\n",
    "model.train(flat_train_images, y_train, alpha=3.5, epochs=3000)\n",
    "acc = model.evaluate(flat_test_images, y_test)\n",
    "print(f\"Test Accuracy: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df7c1ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(flat_train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af36cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
