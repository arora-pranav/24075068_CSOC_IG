{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd43dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8124e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_prime(x):\n",
    "        a = NeuralNetwork.sigmoid(x)\n",
    "        return a * (1 - a)\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        # Stability fix: subtract max for numerical stability\n",
    "        exp_shifted = np.exp(x - np.max(x, axis=0, keepdims=True))\n",
    "        return exp_shifted / np.sum(exp_shifted, axis=0, keepdims=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def cross_entropy_loss(y_true, y_pred):\n",
    "        # Add epsilon to avoid log(0)\n",
    "        eps = 1e-12\n",
    "        return -np.mean(y_true * np.log(y_pred + eps))\n",
    "\n",
    "    @staticmethod\n",
    "    def cross_entropy_derivative(y_true, y_pred):\n",
    "        y_true = y_true.astype(np.float32)\n",
    "        return y_pred - y_true\n",
    "\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.costs = []\n",
    "        self.iters = []\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.Layers = len(layer_sizes)\n",
    "\n",
    "        for k in range(self.Layers - 1):\n",
    "            # Xavier initialization for sigmoid\n",
    "            self.weights.append(np.random.randn(layer_sizes[k + 1], layer_sizes[k]) * np.sqrt(1. / layer_sizes[k]))\n",
    "            self.biases.append(np.zeros((layer_sizes[k + 1], 1)))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.activations = [X]\n",
    "        self.Z = []\n",
    "\n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            z = np.dot(w, self.activations[-1]) + b\n",
    "            self.Z.append(z)\n",
    "\n",
    "            if i == self.Layers - 2:\n",
    "                a = NeuralNetwork.softmax(z)\n",
    "            else:\n",
    "                a = NeuralNetwork.sigmoid(z)\n",
    "\n",
    "            self.activations.append(a)\n",
    "\n",
    "        return self.activations[-1]\n",
    "\n",
    "    def backward(self, X, y):\n",
    "        dw = [None] * (self.Layers - 1)\n",
    "        db = [None] * (self.Layers - 1)\n",
    "        dz = [None] * (self.Layers)\n",
    "\n",
    "        y_pred = self.activations[-1]\n",
    "        cost = NeuralNetwork.cross_entropy_loss(y, y_pred)\n",
    "\n",
    "        # Last layer derivative\n",
    "        dz[-1] = NeuralNetwork.cross_entropy_derivative(y, y_pred)\n",
    "\n",
    "        for l in reversed(range(self.Layers - 1)):\n",
    "            a_prev = self.activations[l]\n",
    "            dz_current = dz[l + 1]\n",
    "\n",
    "            dw[l] = np.dot(dz_current, a_prev.T) / X.shape[1]\n",
    "            db[l] = np.sum(dz_current, axis=1, keepdims=True) / X.shape[1]\n",
    "\n",
    "            if l != 0:\n",
    "                da_prev = np.dot(self.weights[l].T, dz_current)\n",
    "                dz[l] = da_prev * NeuralNetwork.sigmoid_prime(self.Z[l - 1])\n",
    "\n",
    "        return cost, dw, db\n",
    "\n",
    "    def train(self, X, y, alpha1=0.01, epochs=1000, batch_size=32, decay_rate=0.5, decay_interval_percentage = 1):\n",
    "        m = X.shape[1]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            perm = np.random.permutation(m)\n",
    "            X_shuffled = X[:, perm]\n",
    "            y_shuffled = y[:, perm]\n",
    "\n",
    "            # alpha = np.cos((epoch/epochs) * (np.pi / 2)) * alpha1\n",
    "            alpha = alpha1\n",
    "            # alpha = alpha1 * np.exp(-decay_rate * epoch)\n",
    "\n",
    "            epoch_cost = 0\n",
    "            for i in range(0, m, batch_size):\n",
    "                X_batch = X_shuffled[:, i:i + batch_size]\n",
    "                y_batch = y_shuffled[:, i:i + batch_size]\n",
    "\n",
    "                self.forward(X_batch)\n",
    "                cost, dw, db = self.backward(X_batch, y_batch)\n",
    "                epoch_cost += cost\n",
    "\n",
    "                for j in range(self.Layers - 1):\n",
    "                    self.weights[j] -= alpha * dw[j]\n",
    "                    self.biases[j] -= alpha * db[j]\n",
    "\n",
    "            if epoch % (epochs // 10) == 0 or epoch == epochs - 1:\n",
    "                avg_cost = epoch_cost / (m // batch_size)\n",
    "                print(f\"Epoch {epoch}, Cost: {avg_cost:.8f}\")\n",
    "                self.costs.append(avg_cost)\n",
    "                self.iters.append(epoch)\n",
    "\n",
    "            # if epoch % max((decay_interval_percentage * epochs)//100, 1) == 0 and epoch > 0:\n",
    "            #     alpha *= decay_rate\n",
    "                \n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "    def evaluate(self, X, y_true):\n",
    "        y_pred = self.forward(X)\n",
    "        pred_labels = np.argmax(y_pred, axis=0)\n",
    "        true_labels = np.argmax(y_true, axis=0)\n",
    "        accuracy = np.mean(pred_labels == true_labels)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4792a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def load_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n",
    "        return images\n",
    "\n",
    "def load_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        magic, num = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        return labels\n",
    "\n",
    "train_images = load_images('input/train-images.idx3-ubyte')/255\n",
    "train_labels = load_labels('input/train-labels.idx1-ubyte')\n",
    "test_images = load_images('input/t10k-images.idx3-ubyte')/255\n",
    "test_labels = load_labels('input/t10k-labels.idx1-ubyte')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61b316a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_train_images = train_images.reshape(60000, 28*28).T\n",
    "flat_test_images = test_images.reshape(10000, 28*28).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e88ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, num_classes=10):\n",
    "    return np.eye(num_classes)[y].T  # shape: (10, batch_size)\n",
    "\n",
    "y_train = one_hot(train_labels)\n",
    "y_test = one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0274a4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 0.02999496\n",
      "Epoch 9, Cost: 0.00690853\n",
      "Epoch 18, Cost: 0.00420727\n",
      "Epoch 27, Cost: 0.00259467\n",
      "Epoch 36, Cost: 0.00160698\n",
      "Epoch 45, Cost: 0.00101234\n",
      "Epoch 54, Cost: 0.00075981\n",
      "Epoch 63, Cost: 0.00061390\n",
      "Epoch 72, Cost: 0.00053639\n",
      "Epoch 81, Cost: 0.00049071\n",
      "Epoch 89, Cost: 0.00046966\n",
      "Test Accuracy: 96.47%\n",
      "Train Accuracy: 99.96%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork([784, 32, 10])\n",
    "model.train(flat_train_images, y_train, alpha1=5 , epochs=90, batch_size=32, decay_rate=0.9)\n",
    "acc = model.evaluate(flat_test_images, y_test)\n",
    "print(f\"Test Accuracy: {acc * 100:.2f}%\")\n",
    "acc = model.evaluate(flat_train_images, y_train)\n",
    "print(f\"Train Accuracy: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ef7dc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 0.06812535\n",
      "Epoch 20, Cost: 0.02612143\n",
      "Epoch 40, Cost: 0.01974093\n",
      "Epoch 60, Cost: 0.01654301\n",
      "Epoch 80, Cost: 0.01452527\n",
      "Epoch 100, Cost: 0.01334013\n",
      "Epoch 120, Cost: 0.01193555\n",
      "Epoch 140, Cost: 0.01119794\n",
      "Epoch 160, Cost: 0.01045328\n",
      "Epoch 180, Cost: 0.01019849\n",
      "Epoch 199, Cost: 0.00933423\n",
      "Test Accuracy: 94.37%\n",
      "Train Accuracy: 97.58%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork([784, 32, 10])\n",
    "model.train(flat_train_images, y_train, alpha1=6, epochs=200, batch_size=32)\n",
    "acc = model.evaluate(flat_test_images, y_test)\n",
    "print(f\"Test Accuracy: {acc * 100:.2f}%\")\n",
    "acc = model.evaluate(flat_train_images, y_train)\n",
    "print(f\"Train Accuracy: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ab06a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
